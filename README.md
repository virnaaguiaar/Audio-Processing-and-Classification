# Audio Processing and Classification

Este √© um projeto de processamento e classificacao de audio que tamb√©m tem o objetio de ser uma exposi√ß√£o de como funciona uma rede neural convolucional.

O projeto √© dividido em quatro partes que ser√£o expostas nesse readme. Cada parte do c√≥digo est√° marcada com coment√°rios que explicam sua fun√ß√£o.

## üéôÔ∏è Grava√ß√£o 

O c√≥digo √© um sistema de grava√ß√£o de √°udio que:
- Organiza os √°udios em categorias (como "left" e "right");
- Cria uma pasta principal para armazenar os arquivos;
- Grava √°udio usando o navegador e converte para formato WAV;
- Numera automaticamente cada nova grava√ß√£o;
- Salva os arquivos em pastas espec√≠ficas para cada comando;
- Possui um bot√£o para iniciar o processo de grava√ß√£o.


Primeiramente √© necess√°rio criar um mecanismo de grava√ß√£o de √°udio caso voc√™ ainda nao tenha os arquivos de √°udio. Utilizei para esse mecanismo o googleColaboratoy que faz a ponte direta com o googleDrive para salvar os aquivos em pastas espec√≠ficas.

    from google.colab import drive
    drive.mount('/content/drive')

    %cd /content/drive/MyDrive/audio2025/audios


    -Para a pasta de √°udios gravados:

    output_dir = "/content/drive/MyDrive/audio2025/audios/gravados"  
    os.makedirs(output_dir, exist_ok=True)


    - Para a pasta dos espectogramas gerados atrav√©s do processamento do √°udio:

    espectrograma_dir = "/content/drive/MyDrive/audio2025/audios/espectrogramas"


    - Para salvar o modelo:
    
    with open('/content/drive/MyDrive/audio2025/audios/model.tflite', 'wb') as f:
      f.write(tflite_model)

    dado = np.load('/content/drive/MyDrive/audio2025/audios/dados_teste_validacao.npz')

    modelo = tf.keras.models.load_model('/content/drive/MyDrive/audio2025/audios/modelo.keras')

##  üìä Spectograma  
Este c√≥digo realiza o pr√©-processamento de √°udios e gera espectrogramas. 

#### O que s√£o espectogramas?

S√£o representa√ß√µes visuais de frequ√™ncias ao longo do tempo, onde:

- Eixo X: Tempo;
- Eixo Y: frequ√™ncia (escala logar√≠tmica);
- Cores: Intensidade (dB).


O c√≥dio desta se√ß√£o:
- Monta o Google Drive para acessar arquivos;
- Instala e importa bibliotecas necess√°rias (librosa, OpenCV, matplotlib, scipy);
- Aplica um filtro passa-banda para isolar frequ√™ncias entre 100 Hz e 10.000 Hz, removendo ru√≠dos indesejados, usados tamb√©m para remover sil√™ncios do in√≠cio e fim do √°udio;
- Converte o √°udio em espectrogramas;
- Salva os espectrogramas em pastas separadas pelas categoria desejadas;
- Armazena os espectrogramas e seus r√≥tulos em listas para uso futuro.

### ‚Üí Filtragem de Sinais (Filtro Passa-Banda)
 #### O que √©?

 Um filtro passa-banda permite a passagem de frequ√™ncias dentro de uma faixa espec√≠fica (entre fcorte_inf e fcorte_sup), enquanto atenua frequ√™ncias fora dessa faixa.
- Remove ru√≠dos e frequ√™ncias indesejadas (ex.: 50/60 Hz de interfer√™ncia el√©trica).
- Melhora a qualidade do √°udio antes da an√°lise espectral.

#### Como funciona no c√≥digo?

- butter():

    Projeta um filtro Butterworth (resposta suave na banda de passagem).

    Par√¢metros:
  
        order=5 ‚Üí Quanto maior a ordem, mais "√≠ngreme" √© a filtragem.
        btype='band' ‚Üí Define um filtro passa-banda.
        Frequ√™ncias normalizadas (inf_normalz, sup_normalz) para evitar aliasing.

- filtfilt():
  
    Aplica o filtro duas vezes (ida e volta) para evitar atraso de fase (distor√ß√£o temporal).

### ‚Üí Pr√©-Processamento de √Åudio (Librosa)
 #### Opera√ß√µes principais:
 - librosa.stft() (Short-Time Fourier Transform)

    - Divide o sinal em pequenos segmentos e calcula a Transformada de Fourier para cada um.

    - Sa√≠da: Matriz complexa representando magnitudes e fases em diferentes frequ√™ncias ao longo do tempo.

- librosa.amplitude_to_db()

    - Converte amplitudes em decib√©is (dB) (escala logar√≠tmica).

    Motiva√ß√£o:
    - O ouvido humano percebe sons em escala logar√≠tmica.

    - Melhora o contraste em espectrogramas.


### ‚Üí T√≥picos Extra

- Taxa de Amostragem (sr) e Nyquist
    Teorema de Nyquist:
    - Para reconstruir um sinal, a taxa de amostragem deve ser pelo menos o dobro da frequ√™ncia m√°xima presente no sinal.
    Ex.: Se sr=44100 Hz, a maior frequ√™ncia detect√°vel √© 22050 Hz.

- Normaliza√ß√£o de Frequ√™ncias:

    Antes de aplicar o filtro, as frequ√™ncias s√£o normalizadas pela frequ√™ncia de Nyquist para evitar distor√ß√µes no filtro digital.

- Pr√©-requisito para Machine Learning:
  
    - Dados devem estar em formato num√©rico (imagens como arrays)
    - R√≥tulos devem ser codificados (ex.: 0, 1)

- Leitura com OpenCV (cv2.imread()):
  - Converte a imagem em um array NumPy para processamento posterior (ex.: redes neurais);
  - Permite p√≥s-processamento de imagens (redimensionamento, equaliza√ß√£o de histograma);
  - Compat√≠vel com frameworks de deep learning (ex.: TensorFlow, PyTorch).

##  üìä Classifica√ß√£o  

#keras: classifica√ß√£o de multiclasse / sequential: pilha linear de camadas, onde cada camada recebe a sa√≠da da camada anterior

from tensorflow_keras import Sequential

'''
Conv2D: camada convolucional bidimensional, a principal camada

MaxPooling2D: Camada de pooling, que reduz(/2) as dimens√µes da imagem (diminuindo a resolu√ß√£o) = diminuir a complexidade computacional/evitar overfitting

Flatten: "achata" a entrada q √© matriz multidimensional -> vetor de uma √∫nica dimens√£o / (antes de adicionar camadas densas

Dense: Camada densa - cada neur√¥nio est√° conectado a todos os neur√¥nios da camada anterior

Dropout(reguariza√ß√£o): Queima aleatoriamente alguns neur√¥nios durante o treinamento (reduzir o overfitting)

Input: Define a forma da entrada da rede (n√∫mero de pixels da imagem e o n√∫mero de canais de cor)'''
 






#Analisar o desempenho do modelo em termos de falsos positivos e falsos negativos

#Precis√£o: exemplos positivos corretamente classificados olhando os classificados positivos.
#Precis√£o = (Verdadeiros Positivos) / (Verdadeiros Positivos + Falsos Positivos)
#Sensibilidade: exemplos positivos corretamente classificados olhando os que realmente s√£o positivos
#Sensibilidade = (Verdadeiros Positivos) / (Verdadeiros Positivos + Falsos Negativos)






#Adam (Adaptive Moment Estimation): ajusta as taxas de aprendizado para cada par√¢metro da rede, melhorando a efici√™ncia e estabilidade do treinamento
#Sparse...: Fun√ß√£o de perda utilizada em classifica√ß√£o multiclasse. Com (labels) s√£o n√∫meros inteiros (em vez de vetores one-hot)
#from_logits=False: indica que a sa√≠da da rede neural (logits) j√° √© normalizada pelo softmax. // =True: indica que a rede retorna logits n√£o normalizados // Keras ir√° aplicar a softmax automaticamente
#Keras monitorar a porcentagem de previs√µes corretas do modelo

    model.compile(optimizar='adam',
                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
                  metrics=['accuracy'])






#classification_report: resumo completo das principais m√©tricas de desempenho de um modelo de classifica√ß√£o - precis√£o, recall, F1-score, acur√°cia, para cada classe
#confusion_matrix: cria uma matriz de confus√£o - compara√ß√£o entre as previs√µes do modelo e os r√≥tulos reais (cada c√©lula da matriz: n√∫mero de ocorr√™ncias de cada combina√ß√£o de r√≥tulos previstos e reais)
#accuracy_score: (previs√µes corretas)/(total)

