# Audio-Processing-and-Classification

Este Ã© um projeto de processamento e classificacao de audio que tambÃ©m tem o objetio de ser uma exposiÃ§Ã£o de como funciona uma rede neural convolucional.

O projeto Ã© dividido em quatro partes que serÃ£o expostas nesse readme. Cada parte do cÃ³digo estÃ¡ marcada com comentÃ¡rios que explicam sua funÃ§Ã£o.

## ğŸ™ï¸ GravaÃ§Ã£o ğŸ™ï¸

O cÃ³digo Ã© um sistema de gravaÃ§Ã£o de Ã¡udio que:
- Organiza os Ã¡udios em categorias (como "left" e "right");
- Cria uma pasta principal para armazenar os arquivos;
- Grava Ã¡udio usando o navegador e converte para formato WAV;
- Numera automaticamente cada nova gravaÃ§Ã£o;
- Salva os arquivos em pastas especÃ­ficas para cada comando;
- Possui um botÃ£o para iniciar o processo de gravaÃ§Ã£o.


Primeiramente Ã© necessÃ¡rio criar um mecanismo de gravaÃ§Ã£o de Ã¡udio caso vocÃª ainda nao tenha os arquivos de Ã¡udio. Utilizei para esse mecanismo o googleColaboratoy que faz a ponte direta com o googleDrive para salvar os aquivos em pastas especÃ­ficas.

    from google.colab import drive
    drive.mount('/content/drive')

    %cd /content/drive/MyDrive/audio2025/audios


    -Para a pasta de Ã¡udios gravados:

    output_dir = "/content/drive/MyDrive/audio2025/audios/gravados"  
    os.makedirs(output_dir, exist_ok=True)


    - Para a pasta dos espectogramas gerados atravÃ©s do processamento do Ã¡udio:

    espectrograma_dir = "/content/drive/MyDrive/audio2025/audios/espectrogramas"


    - Para salvar o modelo:
    
    with open('/content/drive/MyDrive/audio2025/audios/model.tflite', 'wb') as f:
      f.write(tflite_model)

    dado = np.load('/content/drive/MyDrive/audio2025/audios/dados_teste_validacao.npz')

    modelo = tf.keras.models.load_model('/content/drive/MyDrive/audio2025/audios/modelo.keras')

##  ğŸ“Š Spectograma  ğŸ“Š 
Este cÃ³digo realiza o prÃ©-processamento de Ã¡udios e gera espectrogramas. 

Espectogramas sÃ£o representaÃ§Ãµes visuais de frequÃªncias ao longo do tempo, onde:

- Eixo X: Tempo;
- Eixo Y: frequÃªncia (escala logarÃ­tmica);
- Cores: Intensidade (dB).


O cÃ³dio desta seÃ§Ã£o:
- Monta o Google Drive para acessar arquivos;
- Instala e importa bibliotecas necessÃ¡rias (librosa, OpenCV, matplotlib, scipy);
- Aplica um filtro passa-banda para isolar frequÃªncias entre 100 Hz e 10.000 Hz, removendo ruÃ­dos indesejados, usados tambÃ©m para remover silÃªncios do inÃ­cio e fim do Ã¡udio;
- Converte o Ã¡udio em espectrogramas;
- Salva os espectrogramas em pastas separadas pelas categoria desejadas;
- Armazena os espectrogramas e seus rÃ³tulos em listas para uso futuro.

### â†’ Filtragem de Sinais (Filtro Passa-Banda)
 #### O que Ã©?

 Um filtro passa-banda permite a passagem de frequÃªncias dentro de uma faixa especÃ­fica (entre fcorte_inf e fcorte_sup), enquanto atenua frequÃªncias fora dessa faixa.
- Remove ruÃ­dos e frequÃªncias indesejadas (ex.: 50/60 Hz de interferÃªncia elÃ©trica).
- Melhora a qualidade do Ã¡udio antes da anÃ¡lise espectral.

#### Como funciona no cÃ³digo?

- butter():

    Projeta um filtro Butterworth (resposta suave na banda de passagem).

    ParÃ¢metros:
  
        order=5 â†’ Quanto maior a ordem, mais "Ã­ngreme" Ã© a filtragem.
        btype='band' â†’ Define um filtro passa-banda.
        FrequÃªncias normalizadas (inf_normalz, sup_normalz) para evitar aliasing.

- filtfilt():
  
    Aplica o filtro duas vezes (ida e volta) para evitar atraso de fase (distorÃ§Ã£o temporal).

### â†’ PrÃ©-Processamento de Ãudio (Librosa)
 #### OperaÃ§Ãµes principais:
 - librosa.stft() (Short-Time Fourier Transform)

    - Divide o sinal em pequenos segmentos e calcula a Transformada de Fourier para cada um.

    - SaÃ­da: Matriz complexa representando magnitudes e fases em diferentes frequÃªncias ao longo do tempo.

- librosa.amplitude_to_db()

    - Converte amplitudes em decibÃ©is (dB) (escala logarÃ­tmica).

    MotivaÃ§Ã£o:
    - O ouvido humano percebe sons em escala logarÃ­tmica.

    - Melhora o contraste em espectrogramas.


### â†’ TÃ³picos Extra

- Taxa de Amostragem (sr) e Nyquist
    Teorema de Nyquist:
    - Para reconstruir um sinal, a taxa de amostragem deve ser pelo menos o dobro da frequÃªncia mÃ¡xima presente no sinal.
    Ex.: Se sr=44100 Hz, a maior frequÃªncia detectÃ¡vel Ã© 22050 Hz.

- NormalizaÃ§Ã£o de FrequÃªncias:

    Antes de aplicar o filtro, as frequÃªncias sÃ£o normalizadas pela frequÃªncia de Nyquist para evitar distorÃ§Ãµes no filtro digital.

- PrÃ©-requisito para Machine Learning:
  
    - Dados devem estar em formato numÃ©rico (imagens como arrays)
    - RÃ³tulos devem ser codificados (ex.: 0, 1)

- Leitura com OpenCV (cv2.imread()):

  - Converte a imagem em um array NumPy para processamento posterior (ex.: redes neurais);
  - Permite pÃ³s-processamento de imagens (redimensionamento, equalizaÃ§Ã£o de histograma);
  - CompatÃ­vel com frameworks de deep learning (ex.: TensorFlow, PyTorch).
