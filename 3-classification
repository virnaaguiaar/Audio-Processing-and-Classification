!nvidia-smi
!pip install --upgrade tensorflow keras

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import os
import numpy as np
import cv2
import random
import pandas as pd
import seaborn as sns #heatmap
import matplotlib.pyplot as plt
from tensorflow_keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input
from tensorflow.keras.metrics import Precision, Recall
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from tqdm import tqdm


# Paths
train_dir = '/content/drive/MyDrive/audio2025/audios/spectrograms/train'
test_dir = '/content/drive/MyDrive/audio2025/audios/spectrograms/test'
validation_dir = '/content/drive/MyDrive/audio2025/audios/spectrograms/validation'

DATADIR = [train_dir, test_dir, validation_dir]
CATEGORIES = ["right", "left"]

# Create storage
train_data = []
test_data = []
validation_data = []

for dir in DATADIR:
  for category in CATEGORIES:
    # directory + class = complete path
    path = os.path.join(dir, category)
    # class index to divide/discriminate
    label = CATEGORIES.index(category)

    # Iterate through all files
    for img_file in tqdm(os.listdir(path), desc=f'Loading images from {category} - {DATADIR.index(dir)}', unit = 'image'):
      # Load image in grayscale
      img = cv2.imread(os.path.join(path, img_file), 1)
      # Resize image to 387x231 px
      img = cv2.resize(img, (387, 231))

      # Fill lists with files
      if(dir == train_dir):
        train_data.append([img, label])
      elif(dir == test_dir):
        test_data.append([img, label])
      elif(dir == validation_dir):
        validation_data.append([img, label])

# Data distribution overview
print(len(train_data))
print(len(test_data))
print(len(validation_data))

# Shuffle all files to avoid biased division (like input order in folder)
random.shuffle(train_data)
random.shuffle(test_data)
random.shuffle(validation_data)

# /255: normalize values and improve performance (speed up training and have more numerical stability)
# Images loaded in grayscale: ranges from [0,255]

# Extract only the image (spectrogram) using '_' to ignore 'label' (list = image + label)
X_train = np.array([spec for spec, _ in train_data]) / 255

# Extract only the label using '_' to ignore 'spectrogram' (list = image + label)
y_train = np.array([lab for _, lab in train_data])

X_test = np.array([spec for spec, _ in test_data]) / 255
y_test = np.array([lab for _, lab in test_data])
X_validation = np.array([spec for spec, _ in validation_data]) / 255
y_validation = np.array([lab for _, lab in validation_data])

# '.shape': output array dimensions
# Output: X(number of images, image dimensions, 3 = 3 color RGB)
#         y(number of images, )

print('Shapes:')
print('X_train:', X_train.shape)
print('y_train:', y_train.shape)
print('X_test:', X_test.shape)
print('y_test:', y_test.shape)
print('X_validation:', X_validation.shape)
print('y_validation:', y_validation.shape)


# Save multiple arrays in compressed .npz file
np.savez('/content/drive/MyDrive/audio2025/audios/test_validation_data.npz', X_train=X_train, y_test=y_test, X_validation=X_validation, y_validation=y_validation)

#Keras

# Define shape: (height, width, 3 = 3 color RGB)
input_shape = (231, 387, 3)

model = Sequential()

# Add input layer (so model knows input data dimension)
model.add(Input(shape=input_shape))

# ADD CONVOLUTIONAL LAYERS
# ---First layer (convolutional + pooling)
# (32 filters/kernels, filter size, common activator: REtified Linear Unit)
model.add(Conv2D(32, (3,3), activation='relu'))
# Takes 2x2 region from each image part - selects max value from that region - forms new reduced image
model.add(MaxPooling2D((2,2)))

#---Second layer (convolutional + pooling)
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

#---Third layer (convolutional + pooling)
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

# 'FLATTEN' 2D -> 1D
model.add(Flatten())

# ADD DENSE LAYERS
#---First dense layer + Dropout
# Layer with 512 neurons
model.add(Dense(512, activation='relu'))
# Randomly turns off 50% of neurons to avoid overfitting
model.add(Dropout(0.5))

#---Final layer (dense + Softmax)
model.add(Dense(6, activation='softmax'))


model.compile(optimizar='adam',
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])


# Overview of all model layers, their parameters, output shapes and total number of trainable and non-trainable parameters
model.summary()  


# Train model in Keras
# (input data to learn, labels for each class, train 10 times, give accuracy or loss at each training/epoch)
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_validation, y_validation))


# Use test data to predict output
predictions = model.predict(X_test)

# Show(detailed report(label, returns each label in class with highest probability))
print(classification_report(y_test, predictions.argmax(axis=1)))


# Calculate confusion matrix(labels, predictions)
cm = confusion_matrix(y_test, predictions.argmax(axis=1))

# Figure size (8x6 inches)
plt.figure(figsize=(8, 6))
# heatmap(matrix, add values directly on map, blue tones, decimal, axes with classes)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=CATEGORIES, yticklabels=CATEGORIES)
plt.xlabel('Prediction')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.savefig('/content/drive/MyDrive/audio2025/audios/confusion_matrix.png')
plt.show()

# Training history: track how accuracy and loss evolved through epochs
print(history.history.keys())
print(history.history['accuracy'])
print(history.history['loss'])

# Accuracy plot
plt.plot(history.history['accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.savefig('/content/drive/MyDrive/audio2025/audios/accuracy.png')
plt.show()

# Loss plot
plt.plot(history.history['loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.savefig('/content/drive/MyDrive/audio2025/audios/loss.png')
plt.show()


# Access metrics
metrics = history.history
# Create DataFrame with metrics: a table - column: metric / row: epoch
metrics_df = pd.DataFrame(metrics)
# to_csv(): converts metrics_df DataFrame to CSV file      //index=False: no index
metrics_df.to_csv('/content/drive/MyDrive/audio2025/audios/metrics_manualv2.csv', index=False)

# Convert trained TensorFlow/Keras model -> TensorFlow Lite (TFLite)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save model
with open('/content/drive/MyDrive/audio2025/audios/model.tflite', 'wb') as f:
  f.write(tflite_model)
