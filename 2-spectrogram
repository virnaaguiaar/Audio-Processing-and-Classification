!pip install librosa
!pip install tqdm
!pip install opencv-python # Install the OpenCV library

from google.colab import drive
drive.mount('/content/drive')

from IPython import get_ipython
from IPython.display import display
from scipy.signal import butter, filtfilt
from tqdm import tqdm
import cv2 # Import the cv2 module
import librosa
import os
import numpy as np
import matplotlib.pyplot as plt
 
# Bandpass Filter
def bandpass_filter(data, low_cutoff, high_cutoff, sample_rate, order=5):
    nyquist = 0.5 * sample_rate  # Highest frequency accurately represented in a digitized signal
    low_norm = low_cutoff / nyquist  # Normalize
    high_norm = high_cutoff / nyquist
    b, a = butter(order, [low_norm, high_norm], btype='band')
        # Coefficients: b(numerator) a(denominator) for filter of given 'order', passing frequencies between 'low_norm' and 'high_norm'

    filtered_data = filtfilt(b, a, data)
        # Applies filter twice (forward and backward) to avoid phase delay
    return filtered_data

DATA_DIR = "/content/drive/MyDrive/audio2025/audios/recorded"
os.makedirs(DATA_DIR, exist_ok=True)
CATEGORIES = ["left", "right"]
data = []
spectrogram_dir = "/content/drive/MyDrive/audio2025/audios/spectrograms"
os.makedirs(spectrogram_dir, exist_ok=True)

for category in CATEGORIES:
    # Creates the path
    category_dir = os.path.join(spectrogram_dir, category)

    # Creates directory if it doesn't exist
    os.makedirs(category_dir, exist_ok=True)

    path = os.path.join(DATA_DIR, category)

    # Assigns class labels to each command
    label = CATEGORIES.index(category)

    # Returns list of files in 'path' // tqdm = progress bar // desc = description // unit = unit shown in progress bar
    for audio_file in tqdm(os.listdir(path), desc=f'Loading audios from {category}', unit='audio'):
        # Absolute path of audio (directory + filename)
        audio_path = os.path.join(path, audio_file)

        # y1: audio signal samples, each value is the 'amplitude' at a point in time
        # sample_rate: sampling rate (samples per second)
        y1, sr1 = librosa.load(audio_path)

        # Allow frequencies between 100 Hz and 10,000 Hz to pass // order = filter "sharpness"
        y1_filtered = bandpass_filter(y1, 100, 10000, sr1, order=5)

        # Trimming
        # Remove silence from beginning and end of audio (<20dB = silence)
        y1_trimmed, _ = librosa.effects.trim(y1_filtered, top_db=20)

        # Short-Time Fourier Transform (divides audio and calculates frequency spectrum of each segment)
        amp_y1 = librosa.stft(y1_trimmed)
        # Converts spectrum amplitude to decibels (dB) (logarithmic scale)
        y1_db = librosa.amplitude_to_db(np.abs(amp_y1), ref=np.max)  # (audio spectrogram converted to dB)

        # Check if y1_db has a valid value
        if y1_db is not None:
            # Creates path according to category and saves as PNG
            spectrogram_path = os.path.join(category_dir, f"{os.path.splitext(audio_file)[0]}.png")

            # figure, axis = matplotlib plot with 5x3 inches
            fig1, ax1 = plt.subplots(figsize=(5, 3))
            # Remove axes
            plt.axis('off')
            # Function that displays spectrogram (x=time, y=amplitude)
            librosa.display.specshow(y1_db, x_axis='time', y_axis='log', ax=ax1)
            # Save image (fullscreen, no extra whitespace)
            plt.savefig(spectrogram_path, bbox_inches='tight', pad_inches=0)
            # Close plot to free memory
            plt.close()
            # Load image with OpenCV (read as numerical array for future processing)
            image = cv2.imread(str(spectrogram_path))
            # Spectrogram and label are added to the 'data' list
            data.append([image, label])

spectrograms = []
labels = []
for spec, lab in dado:
  spec_shape = spec.shape
  spectrograms.append(spec)
  labels.append(lab)

labels = np.array(labels)
